{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100\n",
      "loaded 200\n",
      "loaded 300\n",
      "loaded 400\n",
      "loaded 500\n",
      "loaded 600\n",
      "loaded 700\n",
      "loaded 800\n",
      "loaded 900\n",
      "loaded 1000\n",
      "loaded 1100\n",
      "loaded 1200\n",
      "loaded 1300\n",
      "loaded 1400\n",
      "loaded 1500\n",
      "loaded 1600\n",
      "loaded 1700\n",
      "loaded 1800\n",
      "loaded 1900\n",
      "loaded 2000\n",
      "loaded 2100\n",
      "loaded 2200\n",
      "loaded 2300\n",
      "loaded 2400\n",
      "loaded 2500\n",
      "loaded 2600\n",
      "loaded 2700\n",
      "loaded 2800\n",
      "loaded 2900\n",
      "loaded 3000\n",
      "loaded 3100\n",
      "loaded 3200\n",
      "loaded 3300\n",
      "loaded 3400\n",
      "loaded 3500\n",
      "loaded 3600\n",
      "loaded 3700\n",
      "loaded 3800\n",
      "loaded 3900\n",
      "loaded 4000\n",
      "loaded 4100\n",
      "loaded 4200\n",
      "loaded 4300\n",
      "loaded 4400\n",
      "loaded 4500\n",
      "loaded 4600\n",
      "loaded 4700\n",
      "loaded 4800\n",
      "loaded 4900\n",
      "loaded 5000\n",
      "loaded 5100\n",
      "loaded 5200\n",
      "loaded 5300\n",
      "loaded 5400\n",
      "loaded 5500\n",
      "loaded 5600\n",
      "loaded 5700\n",
      "loaded 5800\n",
      "loaded 5900\n",
      "loaded 6000\n",
      "loaded 6100\n",
      "loaded 6200\n",
      "loaded 6300\n",
      "loaded 6400\n",
      "loaded 6500\n",
      "loaded 6600\n",
      "loaded 6700\n",
      "loaded 6800\n",
      "loaded 6900\n",
      "loaded 7000\n",
      "loaded 7100\n",
      "loaded 7200\n",
      "loaded 7300\n",
      "loaded 7400\n",
      "loaded 7500\n",
      "loaded 7600\n",
      "loaded 7700\n",
      "loaded 7800\n",
      "loaded 7900\n",
      "loaded 8000\n",
      "loaded 8100\n",
      "loaded 8200\n",
      "loaded 8300\n",
      "loaded 8400\n",
      "loaded 8500\n",
      "loaded 8600\n",
      "loaded 8700\n",
      "loaded 8800\n",
      "loaded 8900\n",
      "loaded 9000\n",
      "loaded 9100\n",
      "loaded 9200\n",
      "loaded 9300\n",
      "loaded 9400\n",
      "loaded 9500\n",
      "loaded 9600\n",
      "loaded 9700\n",
      "loaded 9800\n",
      "loaded 9900\n",
      "loaded 10000\n",
      "loaded 10100\n",
      "loaded 10200\n",
      "loaded 10300\n",
      "loaded 10400\n",
      "loaded 10500\n",
      "loaded 10600\n",
      "loaded 10700\n",
      "loaded 10800\n",
      "loaded 10900\n",
      "loaded 11000\n",
      "loaded 11100\n",
      "loaded 11200\n",
      "loaded 11300\n",
      "loaded 11400\n",
      "loaded 11500\n",
      "loaded 11600\n",
      "loaded 11700\n",
      "loaded 11800\n",
      "loaded 11900\n",
      "loaded 12000\n",
      "loaded 12100\n",
      "loaded 12200\n",
      "loaded 12300\n",
      "loaded 12400\n",
      "loaded 12500\n",
      "loaded 12600\n",
      "loaded 12700\n",
      "loaded 12800\n",
      "loaded 12900\n",
      "loaded 13000\n",
      "loaded 13100\n",
      "loaded 13200\n",
      "loaded 13300\n",
      "loaded 13400\n",
      "loaded 13500\n",
      "loaded 13600\n",
      "loaded 13700\n",
      "loaded 13800\n",
      "loaded 13900\n",
      "loaded 14000\n",
      "loaded 14100\n",
      "loaded 14200\n",
      "loaded 14300\n",
      "loaded 14400\n",
      "loaded 14500\n",
      "loaded 14600\n",
      "loaded 14700\n",
      "loaded 14800\n",
      "loaded 14900\n",
      "loaded 15000\n",
      "loaded 15100\n",
      "loaded 15200\n",
      "loaded 15300\n",
      "loaded 15400\n",
      "loaded 15500\n",
      "loaded 15600\n",
      "loaded 15700\n",
      "loaded 15800\n",
      "loaded 15900\n",
      "loaded 16000\n",
      "loaded 16100\n"
     ]
    }
   ],
   "source": [
    "d = Data()\n",
    "X_train,y_train = d.get_10()\n",
    "X_cross, y_cross = d.get_dev()\n",
    "X_test,y_test = d.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(742, 3, 96, 128)\n",
      "(742,)\n",
      "(3230, 96, 128, 3)\n",
      "(3230,)\n",
      "(2423, 96, 128, 3)\n",
      "(2423,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.transpose(0, 3, 1, 2)\n",
    "y_train = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_cross.shape)\n",
    "print(y_cross.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = X_train.shape[0]\n",
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "loader_train = DataLoader(train_dataset, batch_size=10,sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "test_dataset = MyCustomDataset(X_test, y_test)\n",
    "loader_test = DataLoader(test_dataset, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    N = X.shape[0]\n",
    "    return X.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            scores = model(Variable(x.float()))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == Variable(y.long())).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "def train(model, optimizer, epochs=6):\n",
    "    loss_arr = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            scores = model(Variable(x.float()))\n",
    "            loss = F.cross_entropy(scores, Variable(y.long()))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss))\n",
    "                loss_arr += [loss.item()]\n",
    "                check_accuracy(loader_train, model)\n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 31.5115\n",
      "Got 107 / 742 correct (14.42)\n",
      "Iteration 10, loss = 465.3200\n",
      "Got 81 / 742 correct (10.92)\n",
      "Iteration 20, loss = 140.3864\n",
      "Got 146 / 742 correct (19.68)\n",
      "Iteration 30, loss = 113.5323\n",
      "Got 104 / 742 correct (14.02)\n",
      "Iteration 40, loss = 133.1652\n",
      "Got 128 / 742 correct (17.25)\n",
      "Iteration 50, loss = 45.0490\n",
      "Got 169 / 742 correct (22.78)\n",
      "Iteration 60, loss = 87.5076\n",
      "Got 199 / 742 correct (26.82)\n",
      "Iteration 70, loss = 54.5097\n",
      "Got 253 / 742 correct (34.10)\n",
      "Iteration 0, loss = 39.4796\n",
      "Got 226 / 742 correct (30.46)\n",
      "Iteration 10, loss = 46.5419\n",
      "Got 265 / 742 correct (35.71)\n",
      "Iteration 20, loss = 36.7251\n",
      "Got 308 / 742 correct (41.51)\n",
      "Iteration 30, loss = 7.5977\n",
      "Got 355 / 742 correct (47.84)\n",
      "Iteration 40, loss = 9.8450\n",
      "Got 355 / 742 correct (47.84)\n",
      "Iteration 50, loss = 8.5891\n",
      "Got 442 / 742 correct (59.57)\n",
      "Iteration 60, loss = 14.2191\n",
      "Got 490 / 742 correct (66.04)\n",
      "Iteration 70, loss = 25.2922\n",
      "Got 491 / 742 correct (66.17)\n",
      "Iteration 0, loss = 12.3611\n",
      "Got 307 / 742 correct (41.37)\n",
      "Iteration 10, loss = 2.1483\n",
      "Got 471 / 742 correct (63.48)\n",
      "Iteration 20, loss = 6.9955\n",
      "Got 592 / 742 correct (79.78)\n",
      "Iteration 30, loss = 6.0913\n",
      "Got 564 / 742 correct (76.01)\n",
      "Iteration 40, loss = 4.2465\n",
      "Got 573 / 742 correct (77.22)\n",
      "Iteration 50, loss = 6.1586\n",
      "Got 594 / 742 correct (80.05)\n",
      "Iteration 60, loss = 4.4955\n",
      "Got 569 / 742 correct (76.68)\n",
      "Iteration 70, loss = 0.7706\n",
      "Got 639 / 742 correct (86.12)\n",
      "Iteration 0, loss = 0.5974\n",
      "Got 548 / 742 correct (73.85)\n",
      "Iteration 10, loss = 0.6220\n",
      "Got 611 / 742 correct (82.35)\n",
      "Iteration 20, loss = 0.0894\n",
      "Got 661 / 742 correct (89.08)\n",
      "Iteration 30, loss = 4.5906\n",
      "Got 650 / 742 correct (87.60)\n",
      "Iteration 40, loss = 0.8163\n",
      "Got 664 / 742 correct (89.49)\n",
      "Iteration 50, loss = 0.5539\n",
      "Got 661 / 742 correct (89.08)\n",
      "Iteration 60, loss = 0.0000\n",
      "Got 662 / 742 correct (89.22)\n",
      "Iteration 70, loss = 2.4144\n",
      "Got 625 / 742 correct (84.23)\n",
      "Iteration 0, loss = 0.3061\n",
      "Got 656 / 742 correct (88.41)\n",
      "Iteration 10, loss = 0.0000\n",
      "Got 674 / 742 correct (90.84)\n",
      "Iteration 20, loss = 0.0033\n",
      "Got 672 / 742 correct (90.57)\n",
      "Iteration 30, loss = 1.5627\n",
      "Got 641 / 742 correct (86.39)\n",
      "Iteration 40, loss = 0.3779\n",
      "Got 668 / 742 correct (90.03)\n",
      "Iteration 50, loss = 2.2603\n",
      "Got 705 / 742 correct (95.01)\n",
      "Iteration 60, loss = 1.5725\n",
      "Got 708 / 742 correct (95.42)\n",
      "Iteration 70, loss = 2.6548\n",
      "Got 711 / 742 correct (95.82)\n",
      "Iteration 0, loss = 0.2987\n",
      "Got 698 / 742 correct (94.07)\n",
      "Iteration 10, loss = 0.0001\n",
      "Got 715 / 742 correct (96.36)\n",
      "Iteration 20, loss = 0.0006\n",
      "Got 713 / 742 correct (96.09)\n",
      "Iteration 30, loss = 0.0000\n",
      "Got 712 / 742 correct (95.96)\n",
      "Iteration 40, loss = 0.0441\n",
      "Got 722 / 742 correct (97.30)\n",
      "Iteration 50, loss = 0.0000\n",
      "Got 729 / 742 correct (98.25)\n",
      "Iteration 60, loss = 0.0025\n",
      "Got 732 / 742 correct (98.65)\n",
      "Iteration 70, loss = 0.0001\n",
      "Got 731 / 742 correct (98.52)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4bd325ef74ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mloss_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set default size of plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image.interpolation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nearest'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image.cmap'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size = 500\n",
    "channel_1 = 16\n",
    "channel_2 = 32\n",
    "learning_rate = 5e-5\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, channel_1, 5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(channel_2 * 96 * 128, 10)\n",
    ") \n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "loss_arr = train(model,optimizer)\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
