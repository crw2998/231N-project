{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100\n",
      "loaded 200\n",
      "loaded 300\n",
      "loaded 400\n",
      "loaded 500\n",
      "loaded 600\n",
      "loaded 700\n",
      "loaded 800\n",
      "loaded 900\n",
      "loaded 1000\n",
      "loaded 1100\n",
      "loaded 1200\n",
      "loaded 1300\n",
      "loaded 1400\n",
      "loaded 1500\n",
      "loaded 1600\n",
      "loaded 1700\n",
      "loaded 1800\n",
      "loaded 1900\n",
      "loaded 2000\n",
      "loaded 2100\n",
      "loaded 2200\n",
      "loaded 2300\n",
      "loaded 2400\n",
      "loaded 2500\n",
      "loaded 2600\n",
      "loaded 2700\n",
      "loaded 2800\n",
      "loaded 2900\n",
      "loaded 3000\n",
      "loaded 3100\n",
      "loaded 3200\n",
      "loaded 3300\n",
      "loaded 3400\n",
      "loaded 3500\n",
      "loaded 3600\n",
      "loaded 3700\n",
      "loaded 3800\n",
      "loaded 3900\n",
      "loaded 4000\n",
      "loaded 4100\n",
      "loaded 4200\n",
      "loaded 4300\n",
      "loaded 4400\n",
      "loaded 4500\n",
      "loaded 4600\n",
      "loaded 4700\n",
      "loaded 4800\n",
      "loaded 4900\n",
      "loaded 5000\n",
      "loaded 5100\n",
      "loaded 5200\n",
      "loaded 5300\n",
      "loaded 5400\n",
      "loaded 5500\n",
      "loaded 5600\n",
      "loaded 5700\n",
      "loaded 5800\n",
      "loaded 5900\n",
      "loaded 6000\n",
      "loaded 6100\n",
      "loaded 6200\n",
      "loaded 6300\n",
      "loaded 6400\n",
      "loaded 6500\n",
      "loaded 6600\n",
      "loaded 6700\n",
      "loaded 6800\n",
      "loaded 6900\n",
      "loaded 7000\n",
      "loaded 7100\n",
      "loaded 7200\n",
      "loaded 7300\n",
      "loaded 7400\n",
      "loaded 7500\n",
      "loaded 7600\n",
      "loaded 7700\n",
      "loaded 7800\n",
      "loaded 7900\n",
      "loaded 8000\n",
      "loaded 8100\n",
      "loaded 8200\n",
      "loaded 8300\n",
      "loaded 8400\n",
      "loaded 8500\n",
      "loaded 8600\n",
      "loaded 8700\n",
      "loaded 8800\n",
      "loaded 8900\n",
      "loaded 9000\n",
      "loaded 9100\n",
      "loaded 9200\n",
      "loaded 9300\n",
      "loaded 9400\n",
      "loaded 9500\n",
      "loaded 9600\n",
      "loaded 9700\n",
      "loaded 9800\n",
      "loaded 9900\n",
      "loaded 10000\n",
      "loaded 10100\n",
      "loaded 10200\n",
      "loaded 10300\n",
      "loaded 10400\n",
      "loaded 10500\n",
      "loaded 10600\n",
      "loaded 10700\n",
      "loaded 10800\n",
      "loaded 10900\n",
      "loaded 11000\n",
      "loaded 11100\n",
      "loaded 11200\n",
      "loaded 11300\n",
      "loaded 11400\n",
      "loaded 11500\n",
      "loaded 11600\n",
      "loaded 11700\n",
      "loaded 11800\n",
      "loaded 11900\n",
      "loaded 12000\n",
      "loaded 12100\n",
      "loaded 12200\n",
      "loaded 12300\n",
      "loaded 12400\n",
      "loaded 12500\n",
      "loaded 12600\n",
      "loaded 12700\n",
      "loaded 12800\n",
      "loaded 12900\n",
      "loaded 13000\n",
      "loaded 13100\n",
      "loaded 13200\n",
      "loaded 13300\n",
      "loaded 13400\n",
      "loaded 13500\n",
      "loaded 13600\n",
      "loaded 13700\n",
      "loaded 13800\n",
      "loaded 13900\n",
      "loaded 14000\n",
      "loaded 14100\n",
      "loaded 14200\n",
      "loaded 14300\n",
      "loaded 14400\n",
      "loaded 14500\n",
      "loaded 14600\n",
      "loaded 14700\n",
      "loaded 14800\n",
      "loaded 14900\n",
      "loaded 15000\n",
      "loaded 15100\n",
      "loaded 15200\n",
      "loaded 15300\n",
      "loaded 15400\n",
      "loaded 15500\n",
      "loaded 15600\n",
      "loaded 15700\n",
      "loaded 15800\n",
      "loaded 15900\n",
      "loaded 16000\n",
      "loaded 16100\n",
      "Cache dump failed.\n"
     ]
    }
   ],
   "source": [
    "d = Data()\n",
    "X_train,y_train = d.get_train()\n",
    "X_cross, y_cross = d.get_dev()\n",
    "X_test,y_test = d.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 240, 320, 3)\n",
      "(100,)\n",
      "(0, 240, 320, 3)\n",
      "(0,)\n",
      "(12921, 240, 320, 3)\n",
      "(12921,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[:100]\n",
    "y_train = y_train[:100]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_cross.shape)\n",
    "print(y_cross.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = X_train.shape[0]\n",
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "loader_train = DataLoader(train_dataset, batch_size=10,sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "test_dataset = MyCustomDataset(X_test, y_test)\n",
    "loader_test = DataLoader(test_dataset, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    N = X.shape[0]\n",
    "    return X.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            scores = model(Variable(x.float()))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == Variable(y.long())).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "def train(model, optimizer, epochs=1):\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()\n",
    "            scores = model(Variable(x.float()))\n",
    "            loss = F.cross_entropy(scores, Variable(y.long()))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy(loader_test, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 100.8970\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_size = 3000\n",
    "learning_rate = 1e-3\n",
    "num_classes = 196\n",
    "\n",
    "model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3*240*320,hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size,num_classes)\n",
    "    )\n",
    "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "train(model,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
