{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100\n",
      "loaded 200\n",
      "loaded 300\n",
      "loaded 400\n",
      "loaded 500\n",
      "loaded 600\n",
      "loaded 700\n",
      "loaded 800\n",
      "loaded 900\n",
      "loaded 1000\n",
      "loaded 1100\n",
      "loaded 1200\n"
     ]
    }
   ],
   "source": [
    "d = Data(first=600, x_transpose=(0, 3, 1, 2))\n",
    "X_train,y_train = d.get_train()\n",
    "X_cross, y_cross = d.get_dev()\n",
    "X_test,y_test = d.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(637, 3, 224, 224)\n",
      "(637,)\n",
      "(196, 3, 224, 224)\n",
      "(196,)\n",
      "(147, 3, 224, 224)\n",
      "(147,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_cross.shape)\n",
    "print(y_cross.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "else:\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    N = X.shape[0]\n",
    "    return X.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = X_train.shape[0]\n",
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "loader_train = DataLoader(train_dataset, batch_size=20,sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cross_dataset = MyCustomDataset(X_cross, y_cross)\n",
    "loader_cross = DataLoader(cross_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            scores = model(Variable(x.float().type(dtypeFloat)))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == Variable(y.long().type(dtypeLong))).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    print(img.shape)\n",
    "    img = img.transpose(1,2,0)\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50\n",
    "print_acc_every = 150\n",
    "show_transformations = False\n",
    "\n",
    "def train(m, optimizer, epochs=15):\n",
    "    loss_arr = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            m.train()\n",
    "            scores = m(Variable(x.float().type(dtypeFloat)))\n",
    "            loss = F.cross_entropy(scores, Variable(y.long().type(dtypeLong)))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss))\n",
    "                loss_arr += [loss.item()]\n",
    "                if (t % print_acc_every == 0):\n",
    "                    print (\"train acc:\")\n",
    "                    check_accuracy(loader_train, m)\n",
    "                    print (\"cross acc:\")\n",
    "                    m.eval()\n",
    "                    check_accuracy(loader_cross, m)\n",
    "                    \n",
    "                    # print transformations\n",
    "                    if show_transformations:\n",
    "                        x_ = x[5][None]\n",
    "                        stn = next(m.modules())[0]\n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        i = 50\n",
    "                        imshow_noax(x_.data.numpy()[0], normalize=False)\n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        stn_out = stn(Variable(x_.float().type(dtypeFloat))).data.numpy()[0]\n",
    "                        imshow_noax(stn_out, normalize=False)\n",
    "                        plt.show()\n",
    "                    \n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_channel_1 = 96\n",
    "attn_channel_2 = 128\n",
    "attn_channel_3 = 256\n",
    "n_class=2\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtraction, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            nn.Conv2d(3, attn_channel_1, 7, stride=1, padding=3), # 224 x 224 x 96\n",
    "            nn.MaxPool2d(2, stride=2), # 112 x 112 x 96\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_1, attn_channel_2, 5, stride=1, padding=2), # 112 x 112 x 128\n",
    "            nn.MaxPool2d(2, stride=2), # 56 x 56 x 128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_2, attn_channel_3, 3, stride=1, padding=1), # 56 x 56 x 256\n",
    "            nn.MaxPool2d(2, stride=2), # 28 x 28 x 256\n",
    "            nn.ReLU(),\n",
    "#             Flatten(),\n",
    "#             nn.Linear(28*28*256, n_class),\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4f47d23a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 2.2e-4\n",
    "num_classes = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    FeatureExtraction(),\n",
    ")\n",
    "if USE_GPU:\n",
    "    model = model.cuda()\n",
    "    \n",
    "# image generation (to see feature map), and also the way to forward pass\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "    img = model(Variable(x.float().type(dtypeFloat)))\n",
    "    img = img[0].data.cpu().numpy()\n",
    "    print (img.shape)\n",
    "    imgplot = plt.imshow(img[100])\n",
    "    break\n",
    "    \n",
    "# optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# loss_arr = train(model, optimizer, 15)\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "# plt.plot(loss_arr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
