{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100\n",
      "loaded 200\n",
      "loaded 300\n",
      "loaded 400\n",
      "loaded 500\n",
      "loaded 600\n",
      "loaded 700\n",
      "loaded 800\n",
      "loaded 900\n",
      "loaded 1000\n"
     ]
    }
   ],
   "source": [
    "#d = Data(first=600, x_transpose=(0, 3, 1, 2))\n",
    "#X_train,y_train = d.get_train()\n",
    "#X_cross, y_cross = d.get_dev()\n",
    "#X_test,y_test = d.get_test()\n",
    "\n",
    "\n",
    "d  = Data()\n",
    "X_train, y_train = d.get_train()\n",
    "X_cross, y_cross = d.get_dev()\n",
    "X_test, y_test = d.get_test()\n",
    "X_train = X_train.transpose((0,3,1,2))\n",
    "X_cross = X_cross.transpose((0,3,1,2))\n",
    "X_test = X_test.transpose((0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCLASS = 196\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 3, 224, 224)\n",
      "(649,)\n",
      "(200, 3, 224, 224)\n",
      "(200,)\n",
      "(150, 3, 224, 224)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_cross.shape)\n",
    "print(y_cross.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "USE_GPU = False\n",
    "if USE_GPU:\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    N = X.shape[0]\n",
    "    return X.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "NUM_TRAIN = X_train.shape[0]\n",
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size,sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)), drop_last = True)\n",
    "\n",
    "cross_dataset = MyCustomDataset(X_cross, y_cross)\n",
    "loader_cross = DataLoader(cross_dataset, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            scores = model(Variable(x.float().type(dtypeFloat)))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == Variable(y.long().type(dtypeLong))).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    print(img.shape)\n",
    "    img = img.transpose(1,2,0)\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50\n",
    "print_acc_every = 150\n",
    "show_transformations = False\n",
    "\n",
    "def train(m, optimizer, epochs=15):\n",
    "    loss_arr = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            m.train()\n",
    "            scores = m(Variable(x.float().type(dtypeFloat)))\n",
    "            loss = F.cross_entropy(scores, Variable(y.long().type(dtypeLong)))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss))\n",
    "                loss_arr += [loss.item()]\n",
    "                if (t % print_acc_every == 0):\n",
    "                    print (\"train acc:\")\n",
    "                    check_accuracy(loader_train, m)\n",
    "                    print (\"cross acc:\")\n",
    "                    m.eval()\n",
    "                    check_accuracy(loader_cross, m)\n",
    "                    \n",
    "                    # print transformations\n",
    "                    if show_transformations:\n",
    "                        x_ = x[5][None]\n",
    "                        stn = next(m.modules())[0]\n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        i = 50\n",
    "                        imshow_noax(x_.data.numpy()[0], normalize=False)\n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        stn_out = stn(Variable(x_.float().type(dtypeFloat))).data.numpy()[0]\n",
    "                        imshow_noax(stn_out, normalize=False)\n",
    "                        plt.show()\n",
    "                    \n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_channel_1 = 96\n",
    "attn_channel_2 = 128\n",
    "attn_channel_3 = 256\n",
    "n_class= NCLASS\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtraction, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            nn.Conv2d(3, attn_channel_1, 7, stride=1, padding=3), # 224 x 224 x 96\n",
    "            nn.MaxPool2d(2, stride=2), # 112 x 112 x 96\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_1, attn_channel_2, 5, stride=1, padding=2), # 112 x 112 x 128\n",
    "            nn.MaxPool2d(2, stride=2), # 56 x 56 x 128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_2, attn_channel_3, 3, stride=1, padding=1), # 56 x 56 x 256\n",
    "            nn.MaxPool2d(2, stride=2), # 28 x 28 x 256\n",
    "            nn.ReLU(),\n",
    "#             Flatten(),\n",
    "#             nn.Linear(28*28*256, n_class),\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, H, W = 256, 28, 28\n",
    "\n",
    "class MapToClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MapToClass, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            Flatten(),\n",
    "            nn.Linear(C * H * W, n_class),\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size=5\n",
    "C, H, W = 256, 28, 28\n",
    "\n",
    "class AttentiveConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentiveConvLSTM, self).__init__()\n",
    "        \n",
    "        self.Tanh = nn.Tanh()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.Conv_Wa = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Ua = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Va = nn.Conv2d(C, 1, filter_size, padding=2)\n",
    "        self.SoftMax_a = nn.Softmax(dim=2)\n",
    "        self.ba = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.Conv_Wi = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Ui = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bi = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "    \n",
    "        self.Conv_Wf = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uf = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bf = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "\n",
    "        self.Conv_Wo = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uo = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bo = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.Conv_Wc = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uc = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bc = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.H0 = Variable(torch.randn(C, H, W, device = device, dtype=dtype, requires_grad=True))\n",
    "        self.C0 = Variable(torch.randn(C, H, W, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # put the forward pass here (iterating through the channels of X)\n",
    "        # iteratively call AttentitiveConvLSTM_step\n",
    "        # Return X', which is the features modified with the attention map\n",
    "        Hprev = self.H0\n",
    "        Cprev = self.C0\n",
    "        Hprev = Hprev.unsqueeze(0)\n",
    "        Cprev = Cprev.unsqueeze(0)\n",
    "        \n",
    "        #####################################################\n",
    "        ################### FUCK VINEET #####################\n",
    "        #####################################################\n",
    "        \n",
    "        for i in range (10):\n",
    "            \n",
    "            # Attention layer\n",
    "            tanh_input = self.Conv_Wa(X) + self.Conv_Ua(Hprev) + self.ba\n",
    "            tanh_output = self.Tanh(tanh_input)\n",
    "            Z_t = self.Conv_Va(tanh_output)\n",
    "#             print (i)\n",
    "#             print (X.size())\n",
    "#             print (Z_t.size())\n",
    "            Z_t_reshaped = Z_t.view(batch_size, 1, -1)\n",
    "            A_t_initial = self.SoftMax_a(Z_t_reshaped)\n",
    "            A_t = A_t_initial.view(batch_size, 1, H, W)\n",
    "            A_t_expanded = A_t.expand(X.size())\n",
    "            X_t = A_t_expanded * X\n",
    "\n",
    "            # LSTM layer\n",
    "            I_t = self.Sigmoid(self.Conv_Wi(X_t) + self.Conv_Ui(Hprev) + self.bi)\n",
    "            F_t = self.Sigmoid(self.Conv_Wf(X_t) + self.Conv_Uf(Hprev) + self.bf)\n",
    "            O_t = self.Sigmoid(self.Conv_Wo(X_t) + self.Conv_Uo(Hprev) + self.bo)\n",
    "            G_t = self.Tanh(self.Conv_Wc(X_t) + self.Conv_Uc(Hprev) + self.bc)\n",
    "\n",
    "            Cprev = Cprev * F_t + I_t * G_t\n",
    "            Hprev = O_t * self.Tanh(Cprev)\n",
    "        \n",
    "        return X_t\n",
    "        \n",
    "        \n",
    "#         tanh_input = F.conv2d(X, self.Wa, padding=2) + F.conv2d(Hprev, self.Ua, padding=2) + self.ba\n",
    "#         Z_t = F.conv2d(nn.Tanh(tanh_input), self.Va, stride=1, padding=2)\n",
    "#         print(Z_t.size())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #         tanh_input1 = F.conv2d(X, (C, C, filter_size, filter_size), stride=1, padding=2)\n",
    "#         tanh_input2 = F.conv2d(Hprev, (C, C, filter_size, filter_size), stride=1, padding=2)\n",
    "#         tanh_input = tanh_input1 + tanh_input2 + self.ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 5.2813\n",
      "train acc:\n",
      "Got 19 / 640 correct (2.97)\n",
      "cross acc:\n",
      "Got 1 / 200 correct (0.50)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCTensorMath.cu:26",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-090e441f7270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mloss_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# set default size of plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e091f8b785d8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(m, optimizer, epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCTensorMath.cu:26"
     ]
    }
   ],
   "source": [
    "learning_rate = 2.2e-4\n",
    "\n",
    "model = nn.Sequential(\n",
    "    FeatureExtraction(),\n",
    "    AttentiveConvLSTM(), # outputs attention map\n",
    "    MapToClass(),\n",
    ")\n",
    "if USE_GPU:\n",
    "    model = model.cuda()\n",
    "    \n",
    "# # image generation (to see feature map), and also the way to forward pass\n",
    "# for t, (x, y) in enumerate(loader_train):\n",
    "#     img = model(Variable(x.float().type(dtypeFloat)))\n",
    "#     img = img[0].data.cpu().numpy()\n",
    "#     print (img.shape)\n",
    "#     imgplot = plt.imshow(img[100])\n",
    "#     break\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_arr = train(model, optimizer, 15)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape)\n",
    "imshow_noax(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
