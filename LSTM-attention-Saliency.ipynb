{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 100\n",
      "loaded 200\n",
      "loaded 300\n",
      "loaded 400\n",
      "loaded 500\n",
      "loaded 600\n",
      "loaded 700\n",
      "loaded 800\n",
      "loaded 900\n",
      "loaded 1000\n",
      "loaded 1100\n",
      "loaded 1200\n",
      "loaded 1300\n",
      "loaded 1400\n",
      "loaded 1500\n",
      "loaded 1600\n",
      "loaded 1700\n",
      "loaded 1800\n",
      "loaded 1900\n",
      "loaded 2000\n",
      "loaded 2100\n",
      "loaded 2200\n",
      "loaded 2300\n",
      "loaded 2400\n",
      "loaded 2500\n",
      "loaded 2600\n",
      "loaded 2700\n",
      "loaded 2800\n",
      "loaded 2900\n",
      "loaded 3000\n",
      "loaded 3100\n",
      "loaded 3200\n",
      "loaded 3300\n",
      "loaded 3400\n",
      "loaded 3500\n",
      "loaded 3600\n",
      "loaded 3700\n",
      "loaded 3800\n",
      "loaded 3900\n",
      "loaded 4000\n"
     ]
    }
   ],
   "source": [
    "d = Data(first=2000, x_transpose=(0, 3, 1, 2))\n",
    "X_train,y_train = d.get_train()\n",
    "X_cross, y_cross = d.get_dev()\n",
    "X_test,y_test = d.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2137, 3, 224, 224)\n",
      "(2137,)\n",
      "(658, 3, 224, 224)\n",
      "(658,)\n",
      "(494, 3, 224, 224)\n",
      "(494,)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_cross.shape)\n",
    "print(y_cross.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    dtypeFloat = torch.cuda.FloatTensor\n",
    "    dtypeLong = torch.cuda.LongTensor\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    dtypeFloat = torch.FloatTensor\n",
    "    dtypeLong = torch.LongTensor\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(X):\n",
    "    N = X.shape[0]\n",
    "    return X.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): \n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "NUM_TRAIN = X_train.shape[0]\n",
    "train_dataset = MyCustomDataset(X_train, y_train)\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)), drop_last = True)\n",
    "\n",
    "train_dataset_check = MyCustomDataset(X_train, y_train)\n",
    "loader_train_check = DataLoader(train_dataset_check, batch_size=150, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)), drop_last = True)\n",
    "\n",
    "NUM_CROSS = X_cross.shape[0]\n",
    "cross_dataset = MyCustomDataset(X_cross, y_cross)\n",
    "loader_cross = DataLoader(cross_dataset, batch_size=batch_size, sampler=sampler.SubsetRandomSampler(range(NUM_CROSS)), drop_last = True)\n",
    "\n",
    "cross_dataset_check = MyCustomDataset(X_cross, y_cross)\n",
    "loader_cross_check = DataLoader(cross_dataset_check, batch_size=150, sampler=sampler.SubsetRandomSampler(range(NUM_CROSS)), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model): \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            scores = model(Variable(x.float().type(dtypeFloat)))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == Variable(y.long().type(dtypeLong))).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    print(img.shape)\n",
    "    img = img.transpose(1,2,0)\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 5\n",
    "print_acc_every = 50\n",
    "show_transformations = False\n",
    "\n",
    "def train(m, optimizer, epochs=15):\n",
    "    loss_arr = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            m.train()\n",
    "            scores = m(Variable(x.float().type(dtypeFloat)))\n",
    "            loss = F.cross_entropy(scores, Variable(y.long().type(dtypeLong)))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss))\n",
    "                loss_arr += [loss.item()]\n",
    "                if (t % print_acc_every == 0):\n",
    "                    print (\"train acc:\")\n",
    "                    check_accuracy(loader_train_check, m)\n",
    "                    print (\"cross acc:\")\n",
    "                    m.eval()\n",
    "                    check_accuracy(loader_cross_check, m)\n",
    "                    \n",
    "                    # print transformations\n",
    "                    if show_transformations:\n",
    "                        x_ = x[5][None]\n",
    "                        stn = next(m.modules())[0]\n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        i = 50\n",
    "                        imshow_noax(x_.data.numpy()[0], normalize=False)\n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        stn_out = stn(Variable(x_.float().type(dtypeFloat))).data.numpy()[0]\n",
    "                        imshow_noax(stn_out, normalize=False)\n",
    "                        plt.show()\n",
    "                    \n",
    "    return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_channel_1 = 96\n",
    "attn_channel_2 = 128\n",
    "attn_channel_3 = 256\n",
    "n_class=2\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtraction, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            nn.Conv2d(3, attn_channel_1, 7, stride=1, padding=3), # 224 x 224 x 96\n",
    "            nn.MaxPool2d(2, stride=2), # 112 x 112 x 96\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_1, attn_channel_2, 5, stride=1, padding=2), # 112 x 112 x 128\n",
    "            nn.MaxPool2d(2, stride=2), # 56 x 56 x 128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(attn_channel_2, attn_channel_3, 3, stride=1, padding=1), # 56 x 56 x 256\n",
    "            nn.MaxPool2d(2, stride=2), # 28 x 28 x 256\n",
    "            nn.ReLU(),\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 2\n",
    "C, H, W = 256, 28, 28\n",
    "\n",
    "class MapToClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MapToClass, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            Flatten(),\n",
    "            nn.Linear(C * H * W, n_class),\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceSaliency(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProduceSaliency, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(            \n",
    "            nn.Conv2d(C, 1, 1, stride=1, padding=0)\n",
    "        )       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_size=5\n",
    "C, H, W = 256, 28, 28\n",
    "\n",
    "class AttentiveConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentiveConvLSTM, self).__init__()\n",
    "        \n",
    "        self.Tanh = nn.Tanh()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.Conv_Wa = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Ua = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Va = nn.Conv2d(C, 1, filter_size, padding=2)\n",
    "        self.SoftMax_a = nn.Softmax(dim=2)\n",
    "        self.ba = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.Conv_Wi = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Ui = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bi = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "    \n",
    "        self.Conv_Wf = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uf = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bf = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "\n",
    "        self.Conv_Wo = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uo = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bo = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.Conv_Wc = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.Conv_Uc = nn.Conv2d(C, C, filter_size, padding=2)\n",
    "        self.bc = Variable(torch.randn(H, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "        self.H0 = Variable(torch.randn(C, H, W, device = device, dtype=dtype, requires_grad=True))\n",
    "        self.C0 = Variable(torch.randn(C, H, W, device = device, dtype=dtype, requires_grad=True))\n",
    "        \n",
    "                \n",
    "    def forward(self, X):\n",
    "        # put the forward pass here (iterating through the channels of X)\n",
    "        # iteratively call AttentitiveConvLSTM_step\n",
    "        # Return X', which is the features modified with the attention map\n",
    "        Hprev = self.H0\n",
    "        Cprev = self.C0\n",
    "        Hprev = Hprev.unsqueeze(0)\n",
    "        Cprev = Cprev.unsqueeze(0)\n",
    "                \n",
    "        for i in range (10):\n",
    "            \n",
    "            # Attention layer\n",
    "            tanh_input = self.Conv_Wa(X) + self.Conv_Ua(Hprev) + self.ba\n",
    "            tanh_output = self.Tanh(tanh_input)\n",
    "            Z_t = self.Conv_Va(tanh_output)\n",
    "#             print (i)\n",
    "#             print (X.size())\n",
    "#             print (Z_t.size())\n",
    "            Z_t_reshaped = Z_t.view(Z_t.size()[0], 1, -1)\n",
    "            A_t_initial = self.SoftMax_a(Z_t_reshaped)\n",
    "            A_t = A_t_initial.view(-1, 1, H, W)\n",
    "            A_t_expanded = A_t.expand(X.size())\n",
    "            X_t = A_t_expanded * X\n",
    "\n",
    "            # LSTM layer\n",
    "            I_t = self.Sigmoid(self.Conv_Wi(X_t) + self.Conv_Ui(Hprev) + self.bi)\n",
    "            F_t = self.Sigmoid(self.Conv_Wf(X_t) + self.Conv_Uf(Hprev) + self.bf)\n",
    "            O_t = self.Sigmoid(self.Conv_Wo(X_t) + self.Conv_Uo(Hprev) + self.bo)\n",
    "            G_t = self.Tanh(self.Conv_Wc(X_t) + self.Conv_Uc(Hprev) + self.bc)\n",
    "\n",
    "            Cprev = Cprev * F_t + I_t * G_t\n",
    "            Hprev = O_t * self.Tanh(Cprev)\n",
    "        \n",
    "        \n",
    "        return X_t\n",
    "        \n",
    "        \n",
    "#         tanh_input = F.conv2d(X, self.Wa, padding=2) + F.conv2d(Hprev, self.Ua, padding=2) + self.ba\n",
    "#         Z_t = F.conv2d(nn.Tanh(tanh_input), self.Va, stride=1, padding=2)\n",
    "#         print(Z_t.size())\n",
    "\n",
    "        #         tanh_input1 = F.conv2d(X, (C, C, filter_size, filter_size), stride=1, padding=2)\n",
    "#         tanh_input2 = F.conv2d(Hprev, (C, C, filter_size, filter_size), stride=1, padding=2)\n",
    "#         tanh_input = tanh_input1 + tanh_input2 + self.ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2.2e-4\n",
    "num_classes = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "    FeatureExtraction(),\n",
    "    AttentiveConvLSTM(), # outputs attention map\n",
    "   # ProduceSaliency(),\n",
    "    MapToClass(),\n",
    ")\n",
    "if USE_GPU:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.6921\n",
      "train acc:\n",
      "Got 1063 / 2100 correct (50.62)\n",
      "cross acc:\n",
      "Got 298 / 600 correct (49.67)\n",
      "Iteration 5, loss = 0.6476\n",
      "Iteration 10, loss = 0.7155\n",
      "Iteration 15, loss = 0.6618\n",
      "Iteration 20, loss = 0.6860\n",
      "Iteration 25, loss = 0.6882\n",
      "Iteration 30, loss = 0.6998\n",
      "Iteration 35, loss = 0.6894\n",
      "Iteration 40, loss = 0.6975\n",
      "Iteration 45, loss = 0.6918\n",
      "Iteration 50, loss = 0.7060\n",
      "train acc:\n",
      "Got 1055 / 2100 correct (50.24)\n",
      "cross acc:\n",
      "Got 304 / 600 correct (50.67)\n",
      "Iteration 55, loss = 0.6890\n",
      "Iteration 60, loss = 0.7255\n",
      "Iteration 65, loss = 0.6974\n",
      "Iteration 70, loss = 0.7264\n",
      "Iteration 75, loss = 0.6937\n",
      "Iteration 80, loss = 0.6843\n",
      "Iteration 85, loss = 0.6935\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "loss_arr = train(model, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = (torch.load(\"model_params.pt\"))\n",
    "\n",
    "# removed = list(saved_model.children())[:-1]\n",
    "# model2= torch.nn.Sequential(*self.removed)\n",
    "\n",
    "\n",
    " #model2 = nn.Sequential(\n",
    "#     model[0],\n",
    "#     model[1],\n",
    "#     ProduceSaliency()\n",
    "#  )\n",
    "\n",
    "# pretrained_state = (torch.load(\"model_params.pt\"))\n",
    "# model_state = model.state_dict()\n",
    "\n",
    "# pretrained_state = { k:v for k,v in pretrained_state.iteritems() if k in model_state and v.size() == model_state[k].size() }\n",
    "# model_state.update(pretrained_state)\n",
    "# self._model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, (x, y) in enumerate(loader_train):\n",
    "#     model_out = model(Variable(x.float().type(dtypeFloat)))\n",
    "    featureExtraction, attention = next(model.modules())[:2]\n",
    "    feature_out = featureExtraction(Variable(x.float().type(dtypeFloat)))\n",
    "    attention_out = attention(feature_out)\n",
    "    \n",
    "    attention_out_numpy = attention_out.data.cpu().numpy()\n",
    "    print (attention_out_numpy.shape)\n",
    "    img = np.mean(attention_out_numpy, axis=1)\n",
    "    print (img.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(img.size())\n",
    "#     img = img[4]\n",
    "#     img = img.data.cpu().numpy()\n",
    "#     img = img.reshape((H,W))\n",
    "    imgplot = plt.imshow(img[0])\n",
    "    img.show()\n",
    "    break\n",
    "# plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams['image.cmap'] = 'gray'\n",
    "# plt.plot(loss_arr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
